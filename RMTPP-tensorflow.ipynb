{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.keras import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad_sequences = preprocessing.sequence.pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'rmtpp-data/real/so/'\n",
    "idx = 1\n",
    "event_train_file = os.path.join(path, f'event-{idx}-train.txt')\n",
    "event_test_file = os.path.join(path, f'event-{idx}-test.txt')\n",
    "time_train_file = os.path.join(path, f'time-{idx}-train.txt')\n",
    "time_test_file = os.path.join(path, f'time-{idx}-test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(event_train_file, 'r') as in_file:\n",
    "    eventTrain = [[int(y) for y in x.strip().split()] for x in in_file]\n",
    "\n",
    "with open(event_test_file, 'r') as in_file:\n",
    "    eventTest = [[int(y) for y in x.strip().split()] for x in in_file]\n",
    "\n",
    "with open(time_train_file, 'r') as in_file:\n",
    "    timeTrain = [[float(y) for y in x.strip().split()] for x in in_file]\n",
    "\n",
    "with open(time_test_file, 'r') as in_file:\n",
    "    timeTest = [[float(y) for y in x.strip().split()] for x in in_file]\n",
    "\n",
    "assert len(timeTrain) == len(eventTrain)\n",
    "assert len(eventTest) == len(timeTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_samples = len(eventTrain)\n",
    "max_seqlen = max(len(x) for x in eventTrain)\n",
    "unique_samples = set()\n",
    "for x in eventTrain + eventTest:\n",
    "    unique_samples = unique_samples.union(x)\n",
    "    \n",
    "maxTime = max(itertools.chain((max(x) for x in timeTrain), (max(x) for x in timeTest)))\n",
    "minTime = min(itertools.chain((min(x) for x in timeTrain), (min(x) for x in timeTest)))\n",
    "# minTime, maxTime = 0, 1\n",
    "\n",
    "eventTrainIn = [x[:-1] for x in eventTrain]\n",
    "eventTrainOut = [x[1:] for x in eventTrain]\n",
    "timeTrainIn = [[(y - minTime) / (maxTime - minTime) for y in x[:-1]] for x in timeTrain]\n",
    "timeTrainOut = [[(y - minTime) / (maxTime - minTime) for y in x[1:]] for x in timeTrain]\n",
    "\n",
    "train_event_in_seq = pad_sequences(eventTrainIn, padding='post')\n",
    "train_event_out_seq = pad_sequences(eventTrainOut, padding='post')\n",
    "train_time_in_seq = pad_sequences(timeTrainIn, dtype=float, padding='post')\n",
    "train_time_out_seq = pad_sequences(timeTrainOut, dtype=float, padding='post')\n",
    "\n",
    "eventTestIn = [x[:-1] for x in eventTest]\n",
    "eventTestOut = [x[1:] for x in eventTest]\n",
    "timeTestIn = [[(y - minTime) / (maxTime - minTime) for y in x[:-1]] for x in timeTest]\n",
    "timeTestOut = [[(y - minTime) / (maxTime - minTime) for y in x[1:]] for x in timeTest]\n",
    "\n",
    "test_event_in_seq = pad_sequences(eventTestIn, padding='post')\n",
    "test_event_out_seq = pad_sequences(eventTestOut, padding='post')\n",
    "test_time_in_seq = pad_sequences(timeTestIn, dtype=float, padding='post')\n",
    "test_time_out_seq = pad_sequences(timeTestOut, dtype=float, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not doing one-hot encoding because TF provides tf.nn.embedding_lookup\n",
    "\n",
    "# nb_events = len(unique_samples)\n",
    "\n",
    "# train_event_out_hot_seq = np.zeros((nb_samples, max_seqlen - 1, nb_events), dtype=int)\n",
    "\n",
    "# for ii, evs in enumerate(eventTrainOut):\n",
    "#     for jj, x in enumerate(evs):\n",
    "#         train_event_out_hot_seq[ii, jj, x - 1] = 1a\n",
    "        \n",
    "# nb_tests = len(eventTest)\n",
    "\n",
    "# max_test_seqlen = max(len(x) for x in eventTest)\n",
    "# test_event_out_hot_seq = np.zeros((nb_tests, max_test_seqlen - 1, nb_events), dtype=int)\n",
    "\n",
    "# for ii, evs in enumerate(eventTestOut):\n",
    "#     for jj, x in enumerate(evs):\n",
    "#         test_event_out_hot_seq[ii, jj, x - 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# assert np.sum(test_event_out_hot_seq) == sum(len(x) for x in eventTestOut)\n",
    "# assert np.sum(train_event_out_hot_seq) == sum(len(x) for x in eventTrainOut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_LAYER_SIZE = 128 # 64, 128, 256, 512, 1024\n",
    "BATCH_SIZE = 28 # 16, 32, 64\n",
    "LEARNING_RATE = 0.1 # 0.1, 0.01, 0.001\n",
    "MOMENTUM = 0.9\n",
    "L2_PENALTY = 0.001\n",
    "EMBED_SIZE = 100 # ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_CATEGORIES = len(unique_samples)\n",
    "FLOAT_TYPE = tf.float32\n",
    "RNN_CELL_TYPE = tf.contrib.rnn.GRUCell\n",
    "BPTT = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "seed = 42\n",
    "RS = np.random.RandomState(seed)\n",
    "scope = \"RMTPP\"\n",
    "\n",
    "with tf.variable_scope(scope):\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        # Make input variables\n",
    "        events_in = tf.placeholder(tf.int32, [BATCH_SIZE, BPTT])\n",
    "        times_in = tf.placeholder(FLOAT_TYPE, [BATCH_SIZE, BPTT])\n",
    "\n",
    "        events_out = tf.placeholder(tf.int32, [BATCH_SIZE, BPTT])\n",
    "        times_out = tf.placeholder(FLOAT_TYPE, [BATCH_SIZE, BPTT])\n",
    "\n",
    "        # Make variables\n",
    "        with tf.variable_scope('hidden_state'):\n",
    "            Wt = tf.get_variable(name='Wt', shape=(1, HIDDEN_LAYER_SIZE), \n",
    "                                 dtype=FLOAT_TYPE)            \n",
    "            # The first row of Wem is merely a placeholder (will not be trained).\n",
    "            Wem = tf.get_variable(name='Wem', shape=(NUM_CATEGORIES + 1, EMBED_SIZE), \n",
    "                                  dtype=FLOAT_TYPE)\n",
    "            Wh = tf.get_variable(name='Wh', shape=(HIDDEN_LAYER_SIZE, HIDDEN_LAYER_SIZE), \n",
    "                                 dtype=FLOAT_TYPE)\n",
    "            bh = tf.get_variable(name='bh', shape=(1, HIDDEN_LAYER_SIZE),\n",
    "                                 dtype=FLOAT_TYPE)\n",
    "            \n",
    "        with tf.variable_scope('output'):\n",
    "            wt = tf.get_variable(name='wt', shape=(1, 1), \n",
    "                                 dtype=FLOAT_TYPE)\n",
    "\n",
    "            Wy = tf.get_variable(name='Wy', shape=(EMBED_SIZE, HIDDEN_LAYER_SIZE), \n",
    "                             dtype=FLOAT_TYPE)\n",
    "\n",
    "            # The first column of Vy is merely a placeholder (will not be trained).\n",
    "            Vy = tf.get_variable(name='Vy', shape=(HIDDEN_LAYER_SIZE, NUM_CATEGORIES + 1),\n",
    "                                 dtype=FLOAT_TYPE)\n",
    "            Vt = tf.get_variable(name='Vt', shape=(HIDDEN_LAYER_SIZE, 1),\n",
    "                                 dtype=FLOAT_TYPE,\n",
    "                                 initializer=tf.uniform_unit_scaling_initializer())\n",
    "            bt = tf.get_variable(name='bt', shape=(1, 1),\n",
    "                                 dtype=FLOAT_TYPE)\n",
    "            bk = tf.get_variable(name='bk', shape=(1, NUM_CATEGORIES + 1),\n",
    "                                 dtype=FLOAT_TYPE)\n",
    "\n",
    "        # Make graph    \n",
    "        # RNNcell = RNN_CELL_TYPE(HIDDEN_LAYER_SIZE)\n",
    "\n",
    "        # Initial state for GRU cells\n",
    "        initial_state = state = tf.zeros([BATCH_SIZE, HIDDEN_LAYER_SIZE], dtype=FLOAT_TYPE, name='hidden_state')\n",
    "\n",
    "        loss = 0.0\n",
    "        batch_ones = tf.ones((BATCH_SIZE, 1), dtype=FLOAT_TYPE)\n",
    "        for i in range(BPTT):\n",
    "            events_embedded = tf.nn.embedding_lookup(Wem, events_in[:, i])\n",
    "            time = tf.expand_dims(times_in[:, i], axis=-1)\n",
    "\n",
    "            # output, state = RNNcell(events_embedded, state)\n",
    "            # TODO Does TF automatically broadcast? Then we'll not need multiplication\n",
    "            # with tf.ones\n",
    "\n",
    "            state = tf.clip_by_value(\n",
    "                tf.matmul(state, Wh) + \n",
    "                tf.matmul(events_embedded, Wy) + \n",
    "                tf.matmul(time, Wt) + \n",
    "                tf.matmul(batch_ones, bh), \n",
    "                0.0, 1e6, \n",
    "                name='h_t')\n",
    "\n",
    "            base_intensity = tf.matmul(batch_ones, bt)\n",
    "            delta_t = tf.expand_dims(times_out[:, i] - times_in[:, i], axis=-1)\n",
    "            log_lambda_ = (tf.matmul(state, Vt) + \n",
    "                           delta_t * wt + \n",
    "                           base_intensity)\n",
    "\n",
    "            lambda_ = tf.exp(tf.minimum(50.0, log_lambda_), name='lambda_')\n",
    "            wt_non_zero = tf.sign(wt) * tf.maximum(1e-6, tf.abs(wt))\n",
    "            log_f_star = (log_lambda_ + \n",
    "                          (1/wt_non_zero) * tf.exp(tf.minimum(50.0, tf.matmul(state, Vt) + base_intensity)) -\n",
    "                          (1/wt_non_zero) * lambda_)\n",
    "\n",
    "            events_pred = tf.nn.softmax(tf.minimum(50.0, \n",
    "                                                   tf.matmul(state, Vy) + batch_ones * bk),\n",
    "                                        name='Pr_events'\n",
    "                                       )\n",
    "\n",
    "            time_loss = log_f_star\n",
    "            mark_loss = tf.expand_dims(\n",
    "                tf.log(\n",
    "                    tf.maximum(1e-6, \n",
    "                        tf.gather_nd(\n",
    "                            events_pred, \n",
    "                            tf.concat([\n",
    "                                tf.expand_dims(tf.range(BATCH_SIZE), -1),\n",
    "                                tf.expand_dims(events_out[:, i], -1)                             \n",
    "                            ], axis=1, name='Pr_next_event'\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                ), axis=-1, name='log_Pr_next_event'\n",
    "            )\n",
    "            step_loss = time_loss + mark_loss\n",
    "\n",
    "            # In the batch some of the sequences may have ended before we get to the\n",
    "            # end of the seq. In such cases, the events will be zero.\n",
    "            # TODO Figure out how to do this with RNNCell, LSTM, etc.\n",
    "            num_events = tf.reduce_sum(tf.where(events_in[:, i] > 0, \n",
    "                                       tf.ones(BATCH_SIZE, dtype=FLOAT_TYPE), \n",
    "                                       tf.zeros(BATCH_SIZE, dtype=FLOAT_TYPE)),\n",
    "                                       name='num_events')\n",
    "            loss -= tf.cond(num_events > 0, \n",
    "                            lambda: tf.reduce_sum(tf.where(events_in[:, i] > 0, \n",
    "                                               tf.squeeze(step_loss) / num_events,\n",
    "                                               tf.zeros(BATCH_SIZE)), name='batch_bptt_loss'),\n",
    "                            lambda: 0.0)\n",
    "\n",
    "        final_state = state\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "        # update = optimizer.minimize(loss)\n",
    "\n",
    "        # Performing manual gradient clipping.\n",
    "        gvs = optimizer.compute_gradients(loss)\n",
    "        # update = optimizer.apply_gradients(gvs)\n",
    "\n",
    "        capped_gvs = [(tf.clip_by_norm(grad, 100.0), var) for grad, var in gvs]\n",
    "        update = optimizer.apply_gradients(capped_gvs)\n",
    "\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        check_nan = tf.add_check_numerics_ops()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Creation of batches and execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterSession.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iterSession = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch... 0\n",
      "Loss on last batch = 825160007.9513018\n",
      "Loss on last batch = 6.474327160478761e+17\n",
      "Loss on last batch = 2.0493850487793584e+17\n",
      "Loss on last batch = 141193462248.3692\n",
      "Loss on last batch = 2.522614200609171e+18\n",
      "Loss on last batch = 1.1854313146611139e+18\n",
      "Loss on last batch = 1.8593636353279263e+18\n",
      "Loss on last batch = 1296907385177359.2\n",
      "Loss on last batch = 8.34440814795948e+17\n",
      "Loss on last batch = 6.682331945587704e+18\n",
      "Loss on last batch = 1975665688909.9126\n",
      "Loss on last batch = 443871990385787.2\n",
      "Loss on last batch = 637247049171641.6\n",
      "Loss on last batch = 1.920611449516902e+16\n",
      "Loss on last batch = 7.995072172576022e+16\n",
      "Loss on last batch = 571.3106479644775\n",
      "Loss on last batch = 405.51602387428284\n",
      "Loss on last batch = 940.1500968933105\n",
      "Loss on last batch = 430496.77731609344\n",
      "Starting epoch... 1\n",
      "Loss on last batch = 576.1623139381409\n",
      "Loss on last batch = 960.4234066009521\n",
      "Loss on last batch = 424.3694438934326\n",
      "Loss on last batch = 414.5264720916748\n",
      "Loss on last batch = 578.6833915710449\n",
      "Loss on last batch = 451.81292724609375\n",
      "Loss on last batch = 546.5746431350708\n",
      "Loss on last batch = 745.7548017501831\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "idxes = list(range(len(eventTrainIn)))\n",
    "\n",
    "rs = np.random.RandomState(seed=42)\n",
    "\n",
    "iterSession.run(init)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    rs.shuffle(idxes)\n",
    "    \n",
    "    print(\"Starting epoch...\", epoch)\n",
    "    \n",
    "    for batch_idx in range(len(idxes) // BATCH_SIZE):\n",
    "        batch_idxes = idxes[batch_idx * BATCH_SIZE:(batch_idx + 1) * BATCH_SIZE]\n",
    "        batch_event_train_in = train_event_in_seq[batch_idxes, :]\n",
    "        batch_event_train_out = train_event_out_seq[batch_idxes, :]\n",
    "        batch_time_train_in = train_time_in_seq[batch_idxes, :]\n",
    "        batch_time_train_out = train_time_out_seq[batch_idxes, :]\n",
    "        \n",
    "        cur_state = np.zeros((BATCH_SIZE, HIDDEN_LAYER_SIZE))\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for bptt_idx in range(0, len(batch_event_train_in[0]) - BPTT, BPTT):\n",
    "            bptt_range = range(bptt_idx, (bptt_idx + BPTT))\n",
    "            bptt_event_in = batch_event_train_in[:, bptt_range]\n",
    "            bptt_event_out = batch_event_train_out[:, bptt_range]\n",
    "            bptt_time_in = batch_time_train_in[:, bptt_range]\n",
    "            bptt_time_out = batch_time_train_out[:, bptt_range]\n",
    "            \n",
    "            feed_dict = {\n",
    "                  initial_state: cur_state,\n",
    "                  events_in: bptt_event_in,\n",
    "                  events_out: bptt_event_out,\n",
    "                  times_in: bptt_time_in,\n",
    "                  times_out: bptt_time_out\n",
    "            }\n",
    "            \n",
    "#             _, _, cur_state, loss_ = \\\n",
    "#                 iterSession.run([check_nan, update, final_state, loss],\n",
    "#                                feed_dict=feed_dict)\n",
    "            _, cur_state, loss_ = \\\n",
    "                iterSession.run([update, final_state, loss],\n",
    "                                feed_dict=feed_dict)\n",
    "            total_loss += loss_\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Loss on last batch = {}'.format(total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v = tf.get_default_graph().get_tensor_by_name('truediv_11:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iterSession.run(num_events, feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('logs', iterSession.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.15257047e+28],\n",
       "       [  4.13777913e+27],\n",
       "       [             nan],\n",
       "       [  4.00074491e+27],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  6.41804373e+27],\n",
       "       [  9.25703779e+28],\n",
       "       [  2.07751234e+28],\n",
       "       [  1.17640731e+24],\n",
       "       [  6.19882375e+12],\n",
       "       [  1.87156031e+12],\n",
       "       [  4.53088586e+28],\n",
       "       [  9.79549677e+27],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  1.94037092e+28],\n",
       "       [  4.33254788e+28],\n",
       "       [  6.58284523e+28],\n",
       "       [  3.65443046e+28],\n",
       "       [  1.85322862e+28],\n",
       "       [  5.40412750e+06],\n",
       "       [  2.81002788e+28],\n",
       "       [  9.31091716e+28],\n",
       "       [             nan],\n",
       "       [  5.79678986e+28],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  7.19456973e+28],\n",
       "       [             nan],\n",
       "       [  1.02156405e+13],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  2.11805504e+28],\n",
       "       [             nan],\n",
       "       [ -1.08889692e-01],\n",
       "       [  1.91996439e+28],\n",
       "       [  5.67606706e+11],\n",
       "       [             nan],\n",
       "       [  4.04616280e+28],\n",
       "       [  2.12102065e+26],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  4.78253179e+28],\n",
       "       [  1.13420677e+28],\n",
       "       [  3.21965067e+28],\n",
       "       [             nan],\n",
       "       [  2.58379772e+28],\n",
       "       [  2.83362130e+28],\n",
       "       [  2.69468385e+28],\n",
       "       [  6.62638490e+09],\n",
       "       [  5.31406706e+20],\n",
       "       [  2.63398343e+27],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  1.47737787e+26],\n",
       "       [  2.76138538e+28],\n",
       "       [             nan],\n",
       "       [  3.60561890e+27],\n",
       "       [  2.87040405e+28],\n",
       "       [  1.03960395e+28],\n",
       "       [             nan],\n",
       "       [ -1.07711010e-01],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  1.55502782e+28],\n",
       "       [             nan],\n",
       "       [  9.70397483e+28],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  3.11763375e+06],\n",
       "       [  1.09251264e+28],\n",
       "       [  6.33595661e+27],\n",
       "       [             nan],\n",
       "       [ -1.35661244e-01],\n",
       "       [  5.28618493e+28],\n",
       "       [  1.41202744e+13],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  1.92803986e+26],\n",
       "       [  1.71526740e+28],\n",
       "       [  1.29090410e+07],\n",
       "       [  5.14516609e+28],\n",
       "       [  2.71518293e+28],\n",
       "       [  5.31893737e+28],\n",
       "       [  3.97477242e+28],\n",
       "       [             nan],\n",
       "       [  6.24766772e+28],\n",
       "       [  5.57731127e+28],\n",
       "       [  4.99870331e+28],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  2.59457889e+28],\n",
       "       [  4.15628650e+28],\n",
       "       [  1.10417417e+28],\n",
       "       [  8.35633705e+28],\n",
       "       [             nan],\n",
       "       [  4.10765037e+28],\n",
       "       [  3.12019315e+28],\n",
       "       [  3.73945005e+28],\n",
       "       [  5.17019747e+28],\n",
       "       [  1.40618532e+28],\n",
       "       [             nan],\n",
       "       [ -7.52212629e-02],\n",
       "       [  5.68190035e+28],\n",
       "       [             nan],\n",
       "       [  6.75569754e+28],\n",
       "       [             nan],\n",
       "       [  5.19751966e+28],\n",
       "       [  5.52056164e+28],\n",
       "       [  3.69296202e+27],\n",
       "       [             nan],\n",
       "       [  3.81327386e+28],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [             nan],\n",
       "       [  6.24183689e+27],\n",
       "       [  1.83306388e+28],\n",
       "       [  4.52383130e+10],\n",
       "       [  7.52472058e+26],\n",
       "       [             nan]], dtype=float32)"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state.eval(feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
